我们不一样，每个人都有不同的境遇，我们不一样的，虽然会经历不同的事情，我们还是期望来生再相遇文章编号： 1003 1003-0077 0077 （20 11 ）00-0000 0000-00
基于卷积神经网络的微博情感倾向性分析 基于卷积神经网络的微博情感倾向性分析 基于卷积神经网络的微博情感倾向性分析 ?
刘龙飞， 杨亮张绍武， 林鸿飞
（大连理工学 信息检索实验室，辽宁 大连 116024116024116024116024116024116024）
摘要： 微博情感倾向性分析旨在发现用户对热点事件的观态度。由于噪声大、 新词多缩写频繁微博情感倾向性分析旨在发现用户对热点事件的观态度。由于噪声大、 新词多缩写频繁微博情感倾向性分析旨在发现用户对热点事件的观态度。由于噪声大、 新词多缩写频繁微博情感倾向性分析旨在发现用户对热点事件的观态度。由于噪声大、 新词多缩写频繁微博情感倾向性分析旨在发现用户对热点事件的观态度。由于噪声大、 新词多缩写频繁微博情感倾向性分析旨在发现用户对热点事件的观态度。由于噪声大、 新词多缩写频繁微博情感倾向性分析旨在发现用户对热点事件的观态度。由于噪声大、 新词多缩写频繁微博情感倾向性分析旨在发现用户对热点事件的观态度。由于噪声大、 新词多缩写频繁有自己的固定搭配、上下文信息限等原因，微博情感倾向性分析是一项挑战工作。本主要探讨 有自己的固定搭配、上下文信息限等原因，微博情感倾向性分析是一项挑战工作。本主要探讨 有自己的固定搭配、上下文信息限等原因，微博情感倾向性分析是一项挑战工作。本主要探讨 有自己的固定搭配、上下文信息限等原因，微博情感倾向性分析是一项挑战工作。本主要探讨 有自己的固定搭配、上下文信息限等原因，微博情感倾向性分析是一项挑战工作。本主要探讨 有自己的固定搭配、上下文信息限等原因，微博情感倾向性分析是一项挑战工作。本主要探讨 有自己的固定搭配、上下文信息限等原因，微博情感倾向性分析是一项挑战工作。本主要探讨 有自己的固定搭配、上下文信息限等原因，微博情感倾向性分析是一项挑战工作。本主要探讨 有自己的固定搭配、上下文信息限等原因，微博情感倾向性分析是一项挑战工作。本主要探讨 有自己的固定搭配、上下文信息限等原因，微博情感倾向性分析是一项挑战工作。本主要探讨 利用卷积神经网络进行微博情感倾向性分析的可， 别将字级词量和作为原始特征利用卷积神经网络进行微博情感倾向性分析的可， 别将字级词量和作为原始特征采用卷积神经网络来发现任务中的特征，在 采用卷积神经网络来发现任务中的特征，在 COAE2014COAE2014COAE2014COAE2014COAE2014COAE2014COAE2014COAE2014任务 4的语料上进行了实验。结果表明，利用字 的语料上进行了实验。结果表明，利用字 的语料上进行了实验。结果表明，利用字 级别词向量及的卷积神经网络分取得了 95.42%95.42%95.42%95.42%95.42%95.42%的准确率和 94.65%94.65%94.65%94.65%94.65%94.65%的准确率。由此可见对于 的准确率。由此可见对于 的准确率。由此可见对于 中文语料而言，利用卷积神经网络进行微 中文语料而言，利用卷积神经网络进行微 中文语料而言，利用卷积神经网络进行微 中文语料而言，利用卷积神经网络进行微 博情感倾向性分析是有效的，且使用字级别词量作为原始特 博情感倾向性分析是有效的，且使用字级别词量作为原始特 博情感倾向性分析是有效的，且使用字级别词量作为原始特 博情感倾向性分析是有效的，且使用字级别词量作为原始特 博情感倾向性分析是有效的，且使用字级别词量作为原始特 博情感倾向性分析是有效的，且使用字级别词量作为原始特 博情感倾向性分析是有效的，且使用字级别词量作为原始特 征会好于使用词级别的向量作为原始特。
关键词： 关键词： 深度学习；情感倾向性分析卷积神经网络词量 深度学习；情感倾向性分析卷积神经网络词量
中图分类号： 中图分类号： 中图分类号： TP391 TP391 TP391 TP391 TP391 TP391 TP391 TP391 TP391 TP391 TP391 TP391 TP391 TP391 TP391 文献标识码： 文献标识码： A
Convolutional Neural Networks for Chinese Micro Convolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese Micro Convolutional Neural Networks for Chinese Micro Convolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese Micro Convolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese Micro Convolutional Neural Networks for Chinese Micro Convolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese Micro Convolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese Micro Convolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese MicroConvolutional Neural Networks for Chinese Micro Convolutional Neural Networks for Chinese Micro-blog Emotional blog Emotional blog Emotional blog Emotional blog Emotional blog Emotional blog Emotional blog Emotional blog Emotional blog Emotional blog Emotional blog Emotional Tendency IdentificationTendency Identification Tendency IdentificationTendency Identification Tendency Identification Tendency Identification Tendency IdentificationTendency IdentificationTendency IdentificationTendency IdentificationTendency Identification Tendency IdentificationTendency IdentificationTendency IdentificationTendency Identification
LIU L LIU LLIU LLIU Longfei ongfeiongfei ongfei, YANG Liang, , YANG Liang,, YANG Liang, , YANG Liang, , YANG Liang,, YANG Liang,, YANG Liang,, YANG Liang, , YANG Liang, ZHANG Shaowu, ZHANG Shaowu, ZHANG Shaowu, ZHANG Shaowu, ZHANG Shaowu, LIN Hongfei LIN Hongfei LIN Hongfei LIN Hongfei
(Information(Information(Information (Information (Information(Information (Information(Information Retrieval LaboratoryRetrieval Laboratory Retrieval LaboratoryRetrieval LaboratoryRetrieval Laboratory Retrieval Laboratory Retrieval LaboratoryRetrieval LaboratoryRetrieval Laboratory Retrieval Laboratory Retrieval Laboratory Retrieval Laboratory, Dalian University of TechnologyDalian University of Technology Dalian University of TechnologyDalian University of Technology Dalian University of Technology Dalian University of TechnologyDalian University of Technology Dalian University of Technology Dalian University of TechnologyDalian University of TechnologyDalian University of Technology Dalian University of TechnologyDalian University of TechnologyDalian University of Technology Dalian University of Technology , DalianDalian DalianDalian , LiaoningLiaoningLiaoning Liaoning 116024116024 116024, ChinaChina China )
Abstract: Abstract: Abstract: Abstract: Abstract: Abstract: Abstract: Abstract: Abstract: Abstract: Chinese microChinese microChinese microChinese microChinese microChinese microChinese microChinese microChinese microChinese microChinese microChinese microChinese micro-blog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency idenblog emotional tendency identi fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude fication aims to discover the user attitude towards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese microtowards hot events. Emotional Tendency identification of Chinese micro-blog messages is blog messages is blog messages is blog messages is blog messages is blog messages is blog messages is blog messages is blog messages is blog messages is blog messages is blog messages is blog messages is blog messages is blog messages is blog messages is blog messages is challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, challenging because of big noise, too many new words, abbreviations frequently, fixed collocation, the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility the limited contextual information that they normally contain. This paper explores feasibility of performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese microof performing Chinese micro-blog sentimeblog sentimeblog sentimeblog sentimeblog sentimeblog sentimeblog sentimeblog sentimeblog sentimeblog sentimeblog sentimeblog sentiment analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to nt analysis by convolutional neural networks. We try to avoid taskavoid taskavoid taskavoid taskavoid taskavoid taskavoid taskavoid taskavoid taskavoid task-specific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedspecific features, separately take character level embedding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embeding and word level embedding ing ing ing as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For as input, and use convolutional neural networks to discover relevant features the tasks. For the COAthe COAthe COAthe COAthe COAthe COAthe COAE 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary E 4th task corpus, the character level CNN achieves a sentiment prediction (in both binary positive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificpositive/negative classificationationationationation) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment ) accuracy of 95.42%, and the word level CNN achieves a sentiment prediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutioprediction accuracy of 94.65%. The results show that the convolutional neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is nal neural networks model is promising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micropromising in Chinese micro-blog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedblog sentiment analysis. For chinese corpus, character level embedding ing ing ing is slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedis slightly better than word level embedding.ing.ing.ing.
Key words:Key words:Key words:Key words:Key words:Key words:Key words:Key words:Key words: deep learningdeep learningdeep learningdeep learningdeep learningdeep learning deep learning deep learningdeep learningdeep learning；emotional tendency identificationemotional tendency identificationemotional tendency identificationemotional tendency identificationemotional tendency identification emotional tendency identificationemotional tendency identificationemotional tendency identification emotional tendency identification emotional tendency identificationemotional tendency identificationemotional tendency identificationemotional tendency identificationemotional tendency identificationemotional tendency identificationemotional tendency identificationemotional tendency identification emotional tendency identificationemotional tendency identificationemotional tendency identification emotional tendency identificationemotional tendency identification emotional tendency identification emotional tendency identificationemotional tendency identification；convolutional neural netconvolutional neural netconvolutional neural netconvolutional neural netconvolutional neural netconvolutional neural net convolutional neural net convolutional neural netconvolutional neural netconvolutional neural netconvolutional neural netconvolutional neural netconvolutional neural netconvolutional neural netconvolutional neural netconvolutional neural net convolutional neural net convolutional neural netconvolutional neural netconvolutional neural networksworksworks works；word embeddingword embeddingword embedding word embeddingword embeddingword embeddingword embeddingword embeddingword embeddingword embeddingword embedding word embedding
1引言
随着社交网络的不断发展人们更愿意通过微博 随着社交网络的不断发展人们更愿意通过微博 随着社交网络的不断发展人们更愿意通过微博 随着社交网络的不断发展人们更愿意通过微博 随着社交网络的不断发展人们更愿意通过微博 随着社交网络的不断发展人们更愿意通过微博 随着社交网络的不断发展人们更愿意通过微博 随着社交网络的不断发展人们更愿意通过微博 随着社交网络的不断发展人们更愿意通过微博 、博客社区来表达自己的观点 发对热博客社区来表达自己的观点 发对热博客社区来表达自己的观点 发对热博客社区来表达自己的观点 发对热博客社区来表达自己的观点 发对热博客社区来表达自己的观点 发对热博客社区来表达自己的观点 发对热博客社区来表达自己的观点 发对热事件的评论从而使通过微博 事件的评论从而使通过微博 事件的评论从而使通过微博 事件的评论从而使通过微博 事件的评论从而使通过微博 事件的评论从而使通过微博 、博客 、影评以及产品价等来了解社交网络用户的情感倾向得 影评以及产品价等来了解社交网络用户的情感倾向得 影评以及产品价等来了解社交网络用户的情感倾向得 影评以及产品价等来了解社交网络用户的情感倾向得 影评以及产品价等来了解社交网络用户的情感倾向得 影评以及产品价等来了解社交网络用户的情感倾向得 影评以及产品价等来了解社交网络用户的情感倾向得 影评以及产品价等来了解社交网络用户的情感倾向得 影评以及产品价等来了解社交网络用户的情感倾向得 影评以及产品价等来了解社交网络用户的情感倾向得 影评以及产品价等来了解社交网络用户的情感倾向得 影评以及产品价等来了解社交网络用户的情感倾向得 到了学术界的广泛关注 到了学术界的广泛关注 到了学术界的广泛关注 到了学术界的广泛关注 根据微博内容 根据微博内容 根据微博内容 进行情感 进行情感 倾向性 倾向性 分析是一个具有挑战性的任务 分析是一个具有挑战性的任务 分析是一个具有挑战性的任务 分析是一个具有挑战性的任务 分析是一个具有挑战性的任务 ，近年 来引发了学者极大的兴趣 来引发了学者极大的兴趣 来引发了学者极大的兴趣 来引发了学者极大的兴趣 来引发了学者极大的兴趣 [1]。
已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾 已有研究所采用的方法大多数都基于词袋模型，而这种无捕获到很关情感倾
? 收稿日期： 收稿日期： 收稿日期： 定稿日期： 定稿日期：
基金项目： 基金项目： 国家自然科学基金资助项目（编号： 国家自然科学基金资助项目（编号： 国家自然科学基金资助项目（编号： 61277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 6140207561277370, 61402075）、国家 ）、国家 ）、国家 863 高科技计划资助项目（编 高科技计划资助项目（编 高科技计划资助项目（编 号： 2006AA01Z1512006AA01Z1512006AA01Z1512006AA01Z1512006AA01Z1512006AA01Z1512006AA01Z1512006AA01Z1512006AA01Z151 2006AA01Z1512006AA01Z151）、辽宁省自然科学基金（编号： ）、辽宁省自然科学基金（编号： ）、辽宁省自然科学基金（编号： 201202031201202031201202031201202031201202031201202031201202031201202031201202031，2014020003201402000320140200032014020003201402000320140200032014020003201402000320140200032014020003）、教育部留学回国人员科研 ）、教育部留学回国人员科研 启动基金和高等学校博士科点专项研资助课题（编号： 启动基金和高等学校博士科点专项研资助课题（编号： 2009004111000220090041110002200900411100022009004111000220090041110002200900411100022009004111000220090041110002200900411100022009004111000220090041110002200900411100022009004111000220090041110002），中央高校基本科研业务 ），中央高校基本科研业务 ），中央高校基本科研业务 费专项资金助。
向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了向性分析的语言现象特征。例如，“反法西斯 联盟击溃了”和“法西斯 击溃了反和“法西斯 击溃了反和“法西斯 击溃了反和“法西斯 击溃了反和“法西斯 击溃了反和“法西斯 击溃了反和“法西斯 击溃了反联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后联盟”这两个词组拥有相同的袋模型表示方法，而前一带 积极感情色彩后有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 有消极的感情色彩。除此之外，还很多研究者使用人工标注数据（词典及句法分析 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 等），虽然采用这些方法可以有效的提高情感分析准确性但由于需要较多人工标注数据 从而限制了这些方法在其他领域以及跨语言的推广 从而限制了这些方法在其他领域以及跨语言的推广 从而限制了这些方法在其他领域以及跨语言的推广 从而限制了这些方法在其他领域以及跨语言的推广 从而限制了这些方法在其他领域以及跨语言的推广 从而限制了这些方法在其他领域以及跨语言的推广 从而限制了这些方法在其他领域以及跨语言的推广 从而限制了这些方法在其他领域以及跨语言的推广 从而限制了这些方法在其他领域以及跨语言的推广 从而限制了这些方法在其他领域以及跨语言的推广 [2]。卷积神经网络模型可以从大量未标注 。卷积神经网络模型可以从大量未标注 。卷积神经网络模型可以从大量未标注 。卷积神经网络模型可以从大量未标注 。卷积神经网络模型可以从大量未标注 。卷积神经网络模型可以从大量未标注 。卷积神经网络模型可以从大量未标注 。卷积神经网络模型可以从大量未标注 。卷积神经网络模型可以从大量未标注 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 的文本中学习到先验知识，避免依赖于具体任务人工特征设计可以在一定程度上解决短 文本上下信息有限的问题。 文本上下信息有限的问题。 文本上下信息有限的问题。 文本上下信息有限的问题。 文本上下信息有限的问题。 文本上下信息有限的问题。
要提取微博 要提取微博 文本特征 文本特征 ，目前主要 目前主要 做法 是对微博进行 微博进行 分词 ，匹配 情感词典 ，选用其中 选用其中 的情 感词或者情的 感词或者情的 感词或者情的 相关得分作为特征， 相关得分作为特征， 相关得分作为特征， 相关得分作为特征， 但是 微博属于 微博属于 短文本 短文本 范畴， 范畴， 噪声大、 噪声大、 新词 多、缩写频繁、 缩写频繁、 缩写频繁、 有自己 的固定搭配、 的固定搭配、 上下文 上下文 信息有限， 信息有限， 对微博 做分词 歧义明显， 歧义明显， 往 得到 的是 不好 的切分。 切分。 比如 ：“我发现了 我发现了 一个 高大上网站 高大上网站 ”，在该 句中，“高大上网站 高大上网站 高大上网站 ”如果 使用 传统 分词技术， 分词技术， 分词技术， 会被 切分为 “高大 “高大 /上/网站 ”或者“高大 或者“高大 或者“高大 或者“高大 /上网 /站”，这样的 这样的 切分 无法 体现 句子的 句子的 正确 语义， 语义， 甚至后 甚至后 一种 切分还 切分还 将“网站 ”切分 导致丢失评价对象 导致丢失评价对象 导致丢失评价对象 导致丢失评价对象 [3]。为了 解决上述问题，本文 解决上述问题，本文 解决上述问题，本文 解决上述问题，本文 引入字级别 引入字级别 特征， 特征， 将单个字作为输入特征， 单个字作为输入特征， 单个字作为输入特征， 单个字作为输入特征， 单个字作为输入特征， 通过多个拥有 通过多个拥有 通过多个拥有 不同 大小卷积核 大小卷积核 大小卷积核 的并行卷积层学习 的并行卷积层学习 的并行卷积层学习 的并行卷积层学习 的并行卷积层学习 微博 文本特征。 文本特征。 文本特征。
本文训练了一个 包含多本文训练了一个 包含多本文训练了一个 包含多本文训练了一个 包含多本文训练了一个 包含多并行 卷积层的神经网络，不同拥有 卷积层的神经网络，不同拥有 卷积层的神经网络，不同拥有 卷积层的神经网络，不同拥有 卷积层的神经网络，不同拥有 卷积层的神经网络，不同拥有 卷积层的神经网络，不同拥有 卷积层的神经网络，不同拥有 卷积层的神经网络，不同拥有 卷积层的神经网络，不同拥有 大小不同的卷积 大小不同的卷积 大小不同的卷积 大小不同的卷积 核。本文分别将字级特征和词作为原始 。本文分别将字级特征和词作为原始 。本文分别将字级特征和词作为原始 。本文分别将字级特征和词作为原始 。本文分别将字级特征和词作为原始 。本文分别将字级特征和词作为原始 。本文分别将字级特征和词作为原始 。本文分别将字级特征和词作为原始 。本文分别将字级特征和词作为原始 。本文分别将字级特征和词作为原始 。本文分别将字级特征和词作为原始 特征 进行了实验， 进行了实验， 进行了实验， 进行了实验， 利用字级别 利用字级别 利用字级别 特征的 特征的 卷积 神经网络取得了 神经网络取得了 神经网络取得了 神经网络取得了 95.42 5.42%的准确率，利用词级别 的准确率，利用词级别 的准确率，利用词级别 的准确率，利用词级别 的准确率，利用词级别 的准确率，利用词级别 特征 的卷积神经网络取得了 的卷积神经网络取得了 的卷积神经网络取得了 的卷积神经网络取得了 的卷积神经网络取得了 的卷积神经网络取得了 94.6 5%的准确率 的准确率 。 实验表明， 实验表明， 实验表明， 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 对于中文语料而言，利用卷积神经网络进行微博情感倾向性分析是有效的且 将 字级别 词向量 词向量 作为 原始 特征 会好于 会好于 将词级别 词级别 词向量作为原始 词向量作为原始 词向量作为原始 词向量作为原始 特征 。
本文 的结构如下 的结构如下 的结构如下 。第二章介绍 。第二章介绍 。第二章介绍 。第二章介绍 了一些相关工作。 了一些相关工作。 了一些相关工作。 了一些相关工作。 了一些相关工作。 第三章详细 第三章详细 第三章详细 介绍了 介绍了 本文 使用的 使用的 卷积 神经 网络 结构 。第四章详细 第四章详细 第四章详细 说明了本文的实验设定 说明了本文的实验设定 说明了本文的实验设定 说明了本文的实验设定 说明了本文的实验设定 ，介绍了 ，介绍了 ，介绍了 实验结果，并对进行了详细 实验结果，并对进行了详细 实验结果，并对进行了详细 实验结果，并对进行了详细 实验结果，并对进行了详细 实验结果，并对进行了详细 实验结果，并对进行了详细 实验结果，并对进行了详细 实验结果，并对进行了详细 实验结果，并对进行了详细 的讨论 。第五章 第五章 是文章的总结 是文章的总结 是文章的总结 。
2 相关工作
2．1 卷积神经网络 卷积神经网络 卷积神经网络
卷积神经网络利用层可以学习局部特征 卷积神经网络利用层可以学习局部特征 卷积神经网络利用层可以学习局部特征 卷积神经网络利用层可以学习局部特征 卷积神经网络利用层可以学习局部特征 卷积神经网络利用层可以学习局部特征 卷积神经网络利用层可以学习局部特征 卷积神经网络利用层可以学习局部特征 卷积神经网络利用层可以学习局部特征 [4]。在自然语言处理中， 。在自然语言处理中， 。在自然语言处理中， 。在自然语言处理中， 。在自然语言处理中， CNNCNNCNN模型在很多 模型在很多 模型在很多 方面取得了很多非常好的成绩，例如语法解析 方面取得了很多非常好的成绩，例如语法解析 方面取得了很多非常好的成绩，例如语法解析 方面取得了很多非常好的成绩，例如语法解析 方面取得了很多非常好的成绩，例如语法解析 方面取得了很多非常好的成绩，例如语法解析 方面取得了很多非常好的成绩，例如语法解析 方面取得了很多非常好的成绩，例如语法解析 方面取得了很多非常好的成绩，例如语法解析 [5]、搜索 词检、搜索 词检、搜索 词检[6]、句子建模 、句子建模 、句子建模 [7]及其他传统的 及其他传统的 及其他传统的 自然语言工作 自然语言工作 自然语言工作 [8]。Cicero dos SantosCicero dos SantosCicero dos Santos Cicero dos Santos Cicero dos Santos Cicero dos Santos Cicero dos Santos 等人 [9 ]提出了 CharSCNNCharSCNN CharSCNN CharSCNNCharSCNN模型，两个卷积层分别学习词 模型，两个卷积层分别学习词 模型，两个卷积层分别学习词 模型，两个卷积层分别学习词 模型，两个卷积层分别学习词 模型，两个卷积层分别学习词 模型，两个卷积层分别学习词 语的构造特征和句子义。 语的构造特征和句子义。 语的构造特征和句子义。 语的构造特征和句子义。 语的构造特征和句子义。 语的构造特征和句子义。 语的构造特征和句子义。
本文与 本文与 Cicero dos SantosCicero dos SantosCicero dos Santos Cicero dos Santos Cicero dos Santos Cicero dos Santos Cicero dos Santos 工作的不同之处在于，本文分别利用字级向量 和词工作的不同之处在于，本文分别利用字级向量 和词工作的不同之处在于，本文分别利用字级向量 和词工作的不同之处在于，本文分别利用字级向量 和词工作的不同之处在于，本文分别利用字级向量 和词工作的不同之处在于，本文分别利用字级向量 和词工作的不同之处在于，本文分别利用字级向量 和词工作的不同之处在于，本文分别利用字级向量 和词工作的不同之处在于，本文分别利用字级向量 和词工作的不同之处在于，本文分别利用字级向量 和词工作的不同之处在于，本文分别利用字级向量 和词工作的不同之处在于，本文分别利用字级向量 和词工作的不同之处在于，本文分别利用字级向量 和词进行实验，而没有学习词语的构造特征。本文与 进行实验，而没有学习词语的构造特征。本文与 进行实验，而没有学习词语的构造特征。本文与 进行实验，而没有学习词语的构造特征。本文与 进行实验，而没有学习词语的构造特征。本文与 进行实验，而没有学习词语的构造特征。本文与 进行实验，而没有学习词语的构造特征。本文与 进行实验，而没有学习词语的构造特征。本文与 进行实验，而没有学习词语的构造特征。本文与 进行实验，而没有学习词语的构造特征。本文与 进行实验，而没有学习词语的构造特征。本文与 进行实验，而没有学习词语的构造特征。本文与 进行实验，而没有学习词语的构造特征。本文与 Cicero dos SantosCicero dos SantosCicero dos SantosCicero dos Santos Cicero dos Santos Cicero dos Santos Cicero dos Santos 工作的另一个不同之处在 工作的另一个不同之处在 工作的另一个不同之处在 工作的另一个不同之处在 工作的另一个不同之处在 工作的另一个不同之处在 于， Cicero dos SantosCicero dos SantosCicero dos Santos Cicero dos Santos Cicero dos Santos Cicero dos Santos Cicero dos Santos 在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同在利用卷积层学习句子特征时，使了大 小单一的核而不同小的卷积核获取特征是不同，本文参考了 小的卷积核获取特征是不同，本文参考了 小的卷积核获取特征是不同，本文参考了 小的卷积核获取特征是不同，本文参考了 小的卷积核获取特征是不同，本文参考了 小的卷积核获取特征是不同，本文参考了 小的卷积核获取特征是不同，本文参考了 小的卷积核获取特征是不同，本文参考了 小的卷积核获取特征是不同，本文参考了 KimKimKim等人的工作 等人的工作 [10[10 ]，利用多个不同大小的卷 ，利用多个不同大小的卷 ，利用多个不同大小的卷 ，利用多个不同大小的卷 ，利用多个不同大小的卷 ，利用多个不同大小的卷 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。 积核学习句子级别的特征向量，然后对进行串接构造新。
2．2 情感分析 情感分析
情感 分析自从 分析自从 分析自从 20022002 年由 Bo Pang o Pango Pang 提出 之后， 之后， 获得了 获得了 很大 程度 的关注， 的关注， 的关注， 特别是在 特别是在 特别是在 线评论 线评论 的情感 倾向性 倾向性 分析 上获得了 上获得了 上获得了 很大的发展 很大的发展 很大的发展 。本文 。本文 主要关注 主要关注 无监督的 无监督的 无监督的 情感分析方法 情感分析方法 情感分析方法 情感分析方法 ，由于不 由于不 需要 大量 标注 语料， 语料， 无监督情感 无监督情感 无监督情感 分析方法 分析方法 一直受到许多 一直受到许多 一直受到许多 研究者的青睐 研究者的青睐 研究者的青睐 ，但 同时 效果 也低于 也低于 有监督 的情感分析方法。 情感分析方法。 情感分析方法。 情感分析方法。 Turney urney [11][11][11] 首次 提出 基于种子 基于种子 词（ex cellent, poor cellent, poorcellent, poor cellent, poor ）的非监督 非监督 学习 方法， 方法， 使 用“excellent” “excellent” “excellent” “excellent” “excellent” 和“poor” “poor” “poor” 两个 种子词 种子词 与未知词在 与未知词在 与未知词在 搜索 网页中的 网页中的 互信息来 信息来 计算 未知词的 未知词的 情感极性 情感极性 ， 并用以 计算 真个文本的 真个文本的 真个文本的 情感 极性。 极性。 后续 的非监督 非监督 情感分析方法 情感分析方法 情感分析方法 大都是 大都是 基于 生成 或已 有的情感 词典 或者 相关资源 相关资源 相关资源 进行 情感分析 情感分析 。罗毅 。罗毅 [3][3] 等人 通过 构建 二级情 二级情 感词典 ，对不同级别情感 不同级别情感 不同级别情感 词 作不同 增强 ，使用 N-gramgramgramgram获取文本特征 获取文本特征 获取文本特征 获取文本特征 ，利用 ，利用 构建的情感词典 构建的情感词典 构建的情感词典 构建的情感词典 构建的情感词典 进行 微博情感倾向性分析 微博情感倾向性分析 微博情感倾向性分析 微博情感倾向性分析 微博情感倾向性分析 微博情感倾向性分析 。 情感词典 情感词典 的 构建过程需要大量的 构建过程需要大量的 构建过程需要大量的 构建过程需要大量的 构建过程需要大量人工 标注，在跨领域应用方面有很大的限制。 标注，在跨领域应用方面有很大的限制。 标注，在跨领域应用方面有很大的限制。 标注，在跨领域应用方面有很大的限制。 标注，在跨领域应用方面有很大的限制。 标注，在跨领域应用方面有很大的限制。 标注，在跨领域应用方面有很大的限制。 标注，在跨领域应用方面有很大的限制。 标注，在跨领域应用方面有很大的限制。 使用 N-gram gram 模型， 当 N较大 时，会导致特征维度 时，会导致特征维度 时，会导致特征维度 时，会导致特征维度 太大而 太大而 难以训练 难以训练 难以训练 。包含多个并行 。包含多个并行 。包含多个并行 。包含多个并行 卷积层的 卷积层的 卷积层的 卷积 神经网 神经网 络通过卷积 络通过卷积 和池化操作， 池化操作， 池化操作， 既充分 利用了 利用了 利用了 N-gram gram 的特征，又不会造成维度 的特征，又不会造成维度 的特征，又不会造成维度 的特征，又不会造成维度 的特征，又不会造成维度 灾难 。
3 卷积神经网络模型
3．1 句子级别的表示和评分 句子级别的表示和评分 句子级别的表示和评分 句子级别的表示和评分 句子级别的表示和评分 句子级别的表示和评分
字级别特征： 级别特征： 级别特征： 以单个字作为句子的基本组成位 单个字作为句子的基本组成位 单个字作为句子的基本组成位 单个字作为句子的基本组成位 单个字作为句子的基本组成位 单个字作为句子的基本组成位 单个字作为句子的基本组成位 ，对 单个字 单个字 训练 词向量。 词向量。 词向量。
词级别特征： 级别特征： 级别特征： 利用 分词器对句子进行， 分词器对句子进行， 分词器对句子进行， 分词器对句子进行， 分词器对句子进行， 分词器对句子进行， 以词（ 包含长度 包含长度 为 1的词） 作为 句子 的基本 的基本 组成单位，对个词训练向量。 组成单位，对个词训练向量。 组成单位，对个词训练向量。 组成单位，对个词训练向量。 组成单位，对个词训练向量。 组成单位，对个词训练向量。 组成单位，对个词训练向量。
以“中国 足球加油 足球加油 足球加油 ！”为例 ，字级别的 级别的 句子 组成为 组成为 “中+国+足+球+加+油+！”，词 级别的 级别的 句子组成为 句子组成为 “中国 +足球 +加油 +！”。
给定包含 给定包含 N个基本单位 基本单位 基本单位 {??1,??2,…????} 的句子 x，本文 ，本文 接下来的工作是 接下来的工作是 接下来的工作是 接下来的工作是 计算 其句子级别的 其句子级别的 其句子级别的 表示 ????????????。字级别句子 。字级别句子 。字级别句子 。字级别句子 的基本单位是 的基本单位是 的基本单位是 的基本单位是 单个 的字，词级别句子基本单位是分之后。 的字，词级别句子基本单位是分之后。 的字，词级别句子基本单位是分之后。 的字，词级别句子基本单位是分之后。 的字，词级别句子基本单位是分之后。 的字，词级别句子基本单位是分之后。 的字，词级别句子基本单位是分之后。 的字，词级别句子基本单位是分之后。 的字，词级别句子基本单位是分之后。 的字，词级别句子基本单位是分之后。 的字，词级别句子基本单位是分之后。 的字，词级别句子基本单位是分之后。 在计算 句子级别的特征时，会遇到两个主要问题 句子级别的特征时，会遇到两个主要问题 句子级别的特征时，会遇到两个主要问题 句子级别的特征时，会遇到两个主要问题 句子级别的特征时，会遇到两个主要问题 句子级别的特征时，会遇到两个主要问题 句子级别的特征时，会遇到两个主要问题 句子级别的特征时，会遇到两个主要问题 句子级别的特征时，会遇到两个主要问题 句子级别的特征时，会遇到两个主要问题 ：不同 ：不同 ：不同 句子的长度不同，重要信息会出 句子的长度不同，重要信息会出 句子的长度不同，重要信息会出 句子的长度不同，重要信息会出 句子的长度不同，重要信息会出 句子的长度不同，重要信息会出 句子的长度不同，重要信息会出 句子的长度不同，重要信息会出 现在句子中的任意位置。 现在句子中的任意位置。 现在句子中的任意位置。 现在句子中的任意位置。 现在句子中的任意位置。 利用卷积 利用卷积 层对句子 建立 模型，计算 模型，计算 模型，计算 句子 级别的特征，可以解决上面 级别的特征，可以解决上面 级别的特征，可以解决上面 级别的特征，可以解决上面 级别的特征，可以解决上面 级别的特征，可以解决上面 级别的特征，可以解决上面 提到的两个问题。 提到的两个问题。 提到的两个问题。 通过卷积 通过卷积 通过卷积 操作可以得到句子中每个基本单位（ 操作可以得到句子中每个基本单位（ 操作可以得到句子中每个基本单位（ 操作可以得到句子中每个基本单位（ 操作可以得到句子中每个基本单位（ 操作可以得到句子中每个基本单位（ 字或者词语） 或者词语） 或者词语） 的局部特征， 局部特征， 局部特征， 然后 对得到的局部特征进行最大 得到的局部特征进行最大 得到的局部特征进行最大 得到的局部特征进行最大 得到的局部特征进行最大 化操作，从而得到一个固定长度的 操作，从而得到一个固定长度的 操作，从而得到一个固定长度的 操作，从而得到一个固定长度的 操作，从而得到一个固定长度的 操作，从而得到一个固定长度的 操作，从而得到一个固定长度的 句子 特征 向量 。
在包含 N个基本单位 基本单位 基本单位 {??1,??2,…????} 的句子 x中，卷积层 卷积层 对每个 对每个 大小 为 ?? 的连续窗口 的连续窗口 的连续窗口 进 行矩阵向量操作。 本文 假定向量 ????∈ ????? 是以 句子中第 n个基本单位为 中心的前后各 (???1)/2 个基本单位 个基本单位 个基本单位 的词向量 词向量 的串接： 的串接： 的串接：
????=(?????(???1)/2 ,…,????+(???1)/2 )?? (1)(1)
卷积层 计算 计算 句子特征向量 句子特征向量 句子特征向量 ???????????? ∈ ???????的第 j个元素的 元素的 过程 如下 ：
[??????????]??=max1<??<??[??????+ ??1]?? (2)
其中 ，??∈ ???????×???? 是该卷积层的 该卷积层的 该卷积层的 权重矩阵 权重矩阵 权重矩阵 。如图 1所示 ，用 该权重 矩阵 计算给定句 计算给定句 计算给定句 子中 每个 基本单位（ 基本单位（ 基本单位（ 基本单位（ 字或词） 或词） 的窗口大小为 窗口大小为 窗口大小为 ?? 的局部信息 的局部信息 ，对句子中所有 ，对句子中所有 ，对句子中所有 ，对句子中所有 基本单位的 基本单位的 窗口 取 最大值，就 最大值，就 最大值，就 抽取 了一个在窗口 一个在窗口 一个在窗口 大小为 大小为 ?? 的条件下 条件下 长度为 ??????的句子 特征向量。 特征向量。 特征向量。 图 1中窗口大 窗口大 小 k为 3。
图 1 基于卷积方法抽取句子级别特征 基于卷积方法抽取句子级别特征
FigFig .1 Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to sentencesentencesentencesentence sentencesentence-level feature extraction level feature extractionlevel feature extraction level feature extraction level feature extractionlevel feature extraction level feature extraction level feature extractionlevel feature extractionlevel feature extractionlevel feature extraction level feature extractionlevel feature extraction level feature extractionlevel feature extraction
卷积窗口的大小 卷积窗口的大小 卷积窗口的大小 ?? 不同， 获取 的局部信息也不同。为此 的局部信息也不同。为此 的局部信息也不同。为此 的局部信息也不同。为此 的局部信息也不同。为此 的局部信息也不同。为此 的局部信息也不同。为此 ，本文利用 ，本文利用 ，本文利用 并行的多个卷积层 并行的多个卷积层 并行的多个卷积层 并行的多个卷积层 并行的多个卷积层 ， 学习不同 学习不同 N-gram gram 的信息 。每个卷积层经过最大 。每个卷积层经过最大 。每个卷积层经过最大 。每个卷积层经过最大 。每个卷积层经过最大 池化操作后都会 池化操作后都会 池化操作后都会 生成 一个固定长度的句子特 一个固定长度的句子特 一个固定长度的句子特 一个固定长度的句子特 一个固定长度的句子特 征向量， 征向量， 本文 将所有 卷积 层生成的 句子 特征向量进行串接，得到一个新的 特征向量进行串接，得到一个新的 句子 特征 向量 [9] 。
包含多个 包含多个 不同窗口 不同窗口 不同窗口 的并行卷积 的并行卷积 的并行卷积 层的架构 层的架构 层的架构 如图 2所示 。
图 2 通过基于不同窗口大小的卷积方法利用多个核抽取句子级别特征 通过基于不同窗口大小的卷积方法利用多个核抽取句子级别特征
Fig.2Fig.2 Fig.2Fig.2 Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to Convolutional approach to sentencesentencesentencesentence sentencesentence-level feature extraction with different filter widths level feature extraction with different filter widthslevel feature extraction with different filter widths level feature extraction with different filter widths level feature extraction with different filter widthslevel feature extraction with different filter widths level feature extraction with different filter widths level feature extraction with different filter widthslevel feature extraction with different filter widthslevel feature extraction with different filter widthslevel feature extraction with different filter widths level feature extraction with different filter widthslevel feature extraction with different filter widths level feature extraction with different filter widthslevel feature extraction with different filter widthslevel feature extraction with different filter widthslevel feature extraction with different filter widthslevel feature extraction with different filter widths level feature extraction with different filter widthslevel feature extraction with different filter widthslevel feature extraction with different filter widthslevel feature extraction with different filter widths level feature extraction with different filter widthslevel feature extraction with different filter widthslevel feature extraction with different filter widths level feature extraction with different filter widthslevel feature extraction with different filter widths level feature extraction with different filter widthslevel feature extraction with different filter widths level feature extraction with different filter widths level feature extraction with different filter widths level feature extraction with different filter widths level feature extraction with different filter widths
其中 ，??1??,??1?? 是模型需要学习的参数， 模型需要学习的参数， 模型需要学习的参数， 模型需要学习的参数， 模型需要学习的参数， 模型需要学习的参数， 卷积 单元 的数量 ??????1?? 是由用户指定的超参数。 由用户指定的超参数。 由用户指定的超参数。 由用户指定的超参数。 由用户指定的超参数。 上下文窗口 的大小 ???? 是由用户指定的 超参数 。max(.)max(.) max(.) 表示 最大化操作。 图中 ??11 用来学习 窗口 大小为 3的给定 的给定 句子的 句子的 特征向量 特征向量 。
如图 2所示 ，本文 在卷积 在卷积 层之后， 之后， 加入了 加入了 ReLU eLU层，将 ReLU eLU作为 激活函数。通过加入 激活函数。通过加入 激活函数。通过加入 激活函数。通过加入 激活函数。通过加入 激活函数。通过加入 激活函数。通过加入 ReLU eLU层可以加速 层可以加速 层可以加速 随机梯度下降的 随机梯度下降的 随机梯度下降的 随机梯度下降的 收敛 速度 [10 ]
将所有窗口生成的 句子特征向量串接后得到所有窗口生成的 句子特征向量串接后得到所有窗口生成的 句子特征向量串接后得到所有窗口生成的 句子特征向量串接后得到所有窗口生成的 句子特征向量串接后得到所有窗口生成的 句子特征向量串接后得到所有窗口生成的 句子特征向量串接后得到所有窗口生成的 句子特征向量串接后得到所有窗口生成的 句子特征向量串接后得到新特征向量如下： 特征向量如下： 特征向量如下： 特征向量如下：
?????????? = ??????????1 ??????????2 …???????????? (3)
其中 ， 表示 串接操作 串接操作 串接操作 ，????????????表示由 上下文窗口大小为 上下文窗口大小为 上下文窗口大小为 上下文窗口大小为 上下文窗口大小为 ????的卷积核通过最大化 卷积核通过最大化 卷积核通过最大化 卷积核通过最大化 卷积核通过最大化 操作之后得到的句子特征向量。 操作之后得到的句子特征向量。 操作之后得到的句子特征向量。 操作之后得到的句子特征向量。 操作之后得到的句子特征向量。 操作之后得到的句子特征向量。
最后 ，表示 句子 x的全局特征 的全局特征 的全局特征 的向量 的向量 ????????????被传递给包含两 传递给包含两 传递给包含两 传递给包含两 个全连接层的 全连接层的 全连接层的 神经 网络进行 网络进行 处理，计算该句子属于每个情感标签 处理，计算该句子属于每个情感标签 处理，计算该句子属于每个情感标签 处理，计算该句子属于每个情感标签 处理，计算该句子属于每个情感标签 处理，计算该句子属于每个情感标签 处理，计算该句子属于每个情感标签 ??∈ ?? 的得分 ：
??(??)= ??3?(??2????????????+??2)+ ??3 (4)
其中，矩阵 其中，矩阵 其中，矩阵 其中，矩阵 其中，矩阵 ??2∈?????? × (?????? 1+ ?????? 2+?+?????? ??)，矩阵 ??3∈?|??| × ?????，向量 ，向量 ，向量 ??2 ∈??????，向量 ??3∈?|??| 是模型需要学习的超参数。激活 模型需要学习的超参数。激活 模型需要学习的超参数。激活 模型需要学习的超参数。激活 模型需要学习的超参数。激活 模型需要学习的超参数。激活 模型需要学习的超参数。激活 模型需要学习的超参数。激活 函数 ?(.) 使用 的正切函数。隐藏层单元目 的正切函数。隐藏层单元目 的正切函数。隐藏层单元目 的正切函数。隐藏层单元目 的正切函数。隐藏层单元目 的正切函数。隐藏层单元目 的正切函数。隐藏层单元目 的正切函数。隐藏层单元目 ????? 是有用户指定的超参数。 有用户指定的超参数。 有用户指定的超参数。 有用户指定的超参数。 有用户指定的超参数。
3．2 模型训练 模型训练
微博 情感倾向性 情感倾向性 情感倾向性 分析本质上是一个 分析本质上是一个 分析本质上是一个 分析本质上是一个 基于 主题 的文本 分类问题， 分类问题， 分类问题， 分类问题， 将微博短文本 微博短文本 微博短文本 做两类分， 两类分， 两类分， 两类分， 最终 归纳到 归纳到 正面 和负面 和负面 两种情感 两种情感 类别中。 类别中。
本文 的模型 是通过最小化 是通过最小化 是通过最小化 训练集 训练集 D上的负对数 负对数 似然 函数 （negative log negative lognegative lognegative log negative lognegative log -likelihoodlikelihoodlikelihood likelihoodlikelihood ）进行
训练。给定 一个 句子 ??，参数集合为 ?? 的模型 对每个情感标签 ??∈ ?? 计算 一个得分 ????(??)??。 为了 将这些 得分 转换 为给定句子的情感标签和模型参数集 给定句子的情感标签和模型参数集 给定句子的情感标签和模型参数集 给定句子的情感标签和模型参数集 给定句子的情感标签和模型参数集 给定句子的情感标签和模型参数集 给定句子的情感标签和模型参数集 ??的条件概率 的条件概率 的条件概率 分布，我们在 分布，我们在 分布，我们在 分布，我们在 所有签 所有签 情感标签 情感标签 ??∈ ?? 的得分进行 得分进行 得分进行 Softmax SoftmaxSoftmax 操作 ：
??(??|??,??)= ??????(??)τΣ??????(??)?????∈?? (5)
对上述公式取 上述公式取 上述公式取 对数： 对数：
log ??(??|??,??)= ????(??)τ?log (Σ??????(??)?????∈??) (6)
本文使用随机梯度下降 本文使用随机梯度下降 本文使用随机梯度下降 本文使用随机梯度下降 本文使用随机梯度下降 （SGDSGDSGD）最小化 最小化 负似然函数 负似然函数 负似然函数 ：
??? Σ?log ??(??|??,??)(??,??)∈?? (7)
其中 ，x（变量 （变量 变为斜体）表示训练预料 变为斜体）表示训练预料 变为斜体）表示训练预料 变为斜体）表示训练预料 变为斜体）表示训练预料 变为斜体）表示训练预料 D的一条句子， 一条句子， 一条句子， y表示 该句子的情感标签 句子的情感标签 句子的情感标签 句子的情感标签 句子的情感标签 。
4 实验
4．1 情感分析数据集 情感分析数据集 情感分析数据集 情感分析数据集
本文采用 本文采用 COAE2014COAE2014COAE2014COAE2014 COAE2014 任务 4微博数据集，该共 微博数据集，该共 微博数据集，该共 微博数据集，该共 微博数据集，该共 微博数据集，该共 40000 40000 条数据，其中官方公布了 条数据，其中官方公布了 条数据，其中官方公布了 条数据，其中官方公布了 条数据，其中官方公布了 条数据，其中官方公布了 5000 条微博的极性。由于没有标准训练集和测试，本文利用该 条微博的极性。由于没有标准训练集和测试，本文利用该 条微博的极性。由于没有标准训练集和测试，本文利用该 条微博的极性。由于没有标准训练集和测试，本文利用该 条微博的极性。由于没有标准训练集和测试，本文利用该 条微博的极性。由于没有标准训练集和测试，本文利用该 条微博的极性。由于没有标准训练集和测试，本文利用该 条微博的极性。由于没有标准训练集和测试，本文利用该 条微博的极性。由于没有标准训练集和测试，本文利用该 条微博的极性。由于没有标准训练集和测试，本文利用该 条微博的极性。由于没有标准训练集和测试，本文利用该 条微博的极性。由于没有标准训练集和测试，本文利用该 5000 5000条数据，进行 条数据，进行 条数据，进行 条数据，进行 10 倍交叉验证。利用 倍交叉验证。利用 倍交叉验证。利用 倍交叉验证。利用 数据集提供的 数据集提供的 数据集提供的 数据集提供的 40000 40000 条数据训练词向量。 数据训练词向量。 数据训练词向量。 数据训练词向量。
表 1 COAE2014COAE2014COAE2014COAE2014COAE2014COAE2014COAE2014COAE2014数据样例
Tab.1 Tab.1 Tab.1 Tab.1 Tab.1 Tab.1 COAE2014 Data sample COAE2014 Data sample COAE2014 Data sampleCOAE2014 Data sampleCOAE2014 Data sampleCOAE2014 Data sampleCOAE2014 Data sample COAE2014 Data sample COAE2014 Data sampleCOAE2014 Data sampleCOAE2014 Data sample
积极
消极
奥迪 车质量值得 信赖 。
奥迪和人寿保险一样都是 垃圾 ！
再不买了三星手机很 好用 ，比较人性化。 ，比较人性化。
三星手机真 垃圾 ，电池一点也不给力。关键时候 ，电池一点也不给力。关键时候 ，电池一点也不给力。关键时候 ，电池一点也不给力。关键时候 手 机自动关。
儿子住院自付部分，保险居然全给报销了 ，这 个保险上的一点也 不亏 啊，嘿。 啊，嘿。
保险这玩意啊，就是他忽悠你交上然后不想教得 保险这玩意啊，就是他忽悠你交上然后不想教得 保险这玩意啊，就是他忽悠你交上然后不想教得 时候退回来 所剩无几 所剩无几 的。
4．2 卷积神经网络 卷积神经网络 卷积神经网络
词向量在 词向量在 卷积神经网络 卷积神经网络 模型 中具有 非常重要的作用。 非常重要的作用。 非常重要的作用。 非常重要的作用。 词向量在 词向量在 训练过程中，可以获取 训练过程中，可以获取 训练过程中，可以获取 训练过程中，可以获取 句 法和语义信息，这在情感分析中是至关重要的 和语义信息，这在情感分析中是至关重要的 和语义信息，这在情感分析中是至关重要的 和语义信息，这在情感分析中是至关重要的 和语义信息，这在情感分析中是至关重要的 和语义信息，这在情感分析中是至关重要的 和语义信息，这在情感分析中是至关重要的 和语义信息，这在情感分析中是至关重要的 和语义信息，这在情感分析中是至关重要的 和语义信息，这在情感分析中是至关重要的 和语义信息，这在情感分析中是至关重要的 [13 ]。最近 。最近 的一些工作 一些工作 一些工作 表明通过使用 表明通过使用 表明通过使用 表明通过使用 无监督学 无监督学 习得到 的词向量 的词向量 ，可以极大的提高 可以极大的提高 可以极大的提高 可以极大的提高 模型 的准确率 的准确率 的准确率 [14 ,15,16 15,16 ]。在本文的实验中利用 在本文的实验中利用 在本文的实验中利用 在本文的实验中利用 在本文的实验中利用 word2vecword2vec word2vec word2vec 工 具[17 ]，进行无监督的词向量学习。 ，进行无监督的词向量学习。 ，进行无监督的词向量学习。 ，进行无监督的词向量学习。 ，进行无监督的词向量学习。 ，进行无监督的词向量学习。 ，进行无监督的词向量学习。 word ord2vec 2vec 实现了 实现了 CBOWCBOWCBOWCBOW（continuous bagcontinuous bag continuous bagcontinuous bag continuous bag -of -wordswords words ）和 SG （skip skip-gram gram ）两种 结构，用于 结构，用于 结构，用于 计算 词语的 词语的 向量 表示。 表示。
4．2．1 字级别的词向量 字级别的词向量 字级别的词向量 字级别的词向量
本文以字作为句子 本文以字作为句子 本文以字作为句子 本文以字作为句子 的基本单位，为每个字训练一词向量。在运行 基本单位，为每个字训练一词向量。在运行 基本单位，为每个字训练一词向量。在运行 基本单位，为每个字训练一词向量。在运行 基本单位，为每个字训练一词向量。在运行 基本单位，为每个字训练一词向量。在运行 基本单位，为每个字训练一词向量。在运行 基本单位，为每个字训练一词向量。在运行 基本单位，为每个字训练一词向量。在运行 基本单位，为每个字训练一词向量。在运行 word2vecword2vec word2vec word2vec 工具过程 工具过程 中，本文设定出现次数超过 中，本文设定出现次数超过 中，本文设定出现次数超过 中，本文设定出现次数超过 中，本文设定出现次数超过 中，本文设定出现次数超过 5次的字会被加入典中。最终得到了一个包含 次的字会被加入典中。最终得到了一个包含 次的字会被加入典中。最终得到了一个包含 次的字会被加入典中。最终得到了一个包含 次的字会被加入典中。最终得到了一个包含 次的字会被加入典中。最终得到了一个包含 次的字会被加入典中。最终得到了一个包含 次的字会被加入典中。最终得到了一个包含 次的字会被加入典中。最终得到了一个包含 次的字会被加入典中。最终得到了一个包含 5200 条目的字 条目的字 条目的字 典。对于没有出现在字中的 符典。对于没有出现在字中的 符典。对于没有出现在字中的 符典。对于没有出现在字中的 符典。对于没有出现在字中的 符典。对于没有出现在字中的 符典。对于没有出现在字中的 符典。对于没有出现在字中的 符词向量 词向量 会被随机初始化。训练过程中 会被随机初始化。训练过程中 会被随机初始化。训练过程中 会被随机初始化。训练过程中 会被随机初始化。训练过程中 会被随机初始化。训练过程中 会被随机初始化。训练过程中 的参数设置 的参数设置 的参数设置 如表 2所示。
4．2．2 词级别的向量 词级别的向量 词级别的向量 词级别的向量
本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 本文首先利用分词工具对语料进行。之后，以作为 句子的 句子的 基本单位，为每个 基本单位，为每个 基本单位，为每个 基本单位，为每个 基本单位，为每个 词训练一个向量。在运行 词训练一个向量。在运行 词训练一个向量。在运行 词训练一个向量。在运行 词训练一个向量。在运行 词训练一个向量。在运行 word2vecword2vec word2vec word2vec 工具过 程中，本文设定出现次数超工具过 程中，本文设定出现次数超工具过 程中，本文设定出现次数超工具过 程中，本文设定出现次数超工具过 程中，本文设定出现次数超工具过 程中，本文设定出现次数超工具过 程中，本文设定出现次数超工具过 程中，本文设定出现次数超5次的词会被加 次的词会被加 次的词会被加
入字典中。最终得到了一个包含 入字典中。最终得到了一个包含 入字典中。最终得到了一个包含 入字典中。最终得到了一个包含 入字典中。最终得到了一个包含 入字典中。最终得到了一个包含 入字典中。最终得到了一个包含 19020 19020 条目的 字典。对于没有出现在中词语条目的 字典。对于没有出现在中词语条目的 字典。对于没有出现在中词语条目的 字典。对于没有出现在中词语条目的 字典。对于没有出现在中词语条目的 字典。对于没有出现在中词语条目的 字典。对于没有出现在中词语条目的 字典。对于没有出现在中词语条目的 字典。对于没有出现在中词语条目的 字典。对于没有出现在中词语条目的 字典。对于没有出现在中词语词向量 词向量 会被随机初始化。训练过程中 会被随机初始化。训练过程中 会被随机初始化。训练过程中 会被随机初始化。训练过程中 会被随机初始化。训练过程中 会被随机初始化。训练过程中 的参数 的参数 设置 如表 2所示 。
表 2 字级别和 词级别 word2vecword2vecword2vecword2vecword2vecword2vecword2vecword2vec可调参数的设置
Tab.Tab.Tab.Tab.2 Character CharacterCharacter CharacterCharacter -level and word level and wordlevel and word level and wordlevel and wordlevel and wordlevel and wordlevel and wordlevel and wordlevel and word -level word2vec hyper level word2vec hyperlevel word2vec hyper level word2vec hyperlevel word2vec hyperlevel word2vec hyper level word2vec hyperlevel word2vec hyperlevel word2vec hyperlevel word2vec hyperlevel word2vec hyperlevel word2vec hyperlevel word2vec hyperlevel word2vec hyperlevel word2vec hyperlevel word2vec hyper-parametersparametersparameters parametersparametersparameters
可调参数
值
词向量维度
300
迭代次数
算法选择
1
skipskipskipskip-gramgramgramgram
上下文窗口
10
采样值
1e -3
4．2．3 超参数 超参数
本文对 多个卷积 多个卷积 神经 网络模型进行了实验 网络模型进行了实验 网络模型进行了实验 网络模型进行了实验 。训练过程中采用 训练过程中采用 训练过程中采用 训练过程中采用 AdadeltaAdadelta AdadeltaAdadelta更新规则 更新规则 更新规则 [18[18 ]，对 乱序的微批次样本中进行随机梯度下降 乱序的微批次样本中进行随机梯度下降 乱序的微批次样本中进行随机梯度下降 乱序的微批次样本中进行随机梯度下降 乱序的微批次样本中进行随机梯度下降 乱序的微批次样本中进行随机梯度下降 乱序的微批次样本中进行随机梯度下降 乱序的微批次样本中进行随机梯度下降 （SGDSGDSGD）。模型 的其他参数如表 的其他参数如表 的其他参数如表 的其他参数如表 3所示 。
表 3 模型 参数设置
Tab.Tab.Tab.Tab.3 Model hyperModel hyperModel hyperModel hyperModel hyper Model hyperModel hyperModel hyperModel hyperModel hyper-parametersparametersparameters parametersparametersparameters
参数
参数 名
字级别
词级别
??
词向量维度
300
300
??1
上下文 窗口大小
2
2
??????11
卷积 单元数量
100
100
??2
上下文 窗口大小
3
3
??????12
卷积单元数量
100
100
??3
上下文 窗口大小
5
5
??????13
卷积 单元数量
100
100
?????
隐藏层单元 数量
300
300
4．3 对比实验 对比实验
本文与 传统的词袋模型进行了对比 传统的词袋模型进行了对比 传统的词袋模型进行了对比 传统的词袋模型进行了对比 传统的词袋模型进行了对比 传统的词袋模型进行了对比 ，将 N-gram gram 词袋 向量作为输入 向量作为输入 向量作为输入 ，利用线性核 利用线性核 利用线性核 SVMSVMSVM进行 了微博 情感倾向性分类。 情感倾向性分类。 情感倾向性分类。 情感倾向性分类。 情感倾向性分类。 情感倾向性分类。 情感倾向性分类。 情感倾向性分类。 本文 对三种类型的 对三种类型的 对三种类型的 对三种类型的 对三种类型的 对三种类型的 N-gram gram 词袋模型进行了 词袋模型进行了 词袋模型进行了 词袋模型进行了 词袋模型进行了 词袋模型进行了 词袋模型进行了 测试： 测试： 测试： bow1 bow1 ??∈{1} ，bow 2 ??∈{1,2}，bow3 ??∈{1,2,3}。其中 ，bow1bow1 是传统的词袋向量， 传统的词袋向量， 传统的词袋向量， 传统的词袋向量， bow2 bow2 向量 中的每一个元素表示 中的每一个元素表示 中的每一个元素表示 中的每一个元素表示 uni -gramgram 或 bi -gram 特征 ，而 bowbow 3向量 中的 每一个 每一个 元素 表示 uni -gram 、 bi -gram gram或者 tri -gram gram特征，其中 特征，其中 特征，其中 的特征值 的特征值 的特征值 使用 TF -IDF 方法 计算 ，并使用了 并使用了 并使用了 libSVM libSVM进行 SVM 的实验 [19 ]。
4．4 结果与讨论 结果与讨论 结果与讨论
本文对多个模型进行了实验。 本文对多个模型进行了实验。 本文对多个模型进行了实验。 本文对多个模型进行了实验。 本文对多个模型进行了实验。 本文对多个模型进行了实验。
? SVM SVM bow1 bow1bow1：向量 特征 是 uniuni -gram gramgram特征 ，利用 ，利用 SVMSVMSVM分类。
? SVM bow SVM bow SVM bow2：向量 特征是 特征是 uniuni -gram gramgram和 bi -gram gramgram特征，利用 SVMSVMSVM分类。 分类。
? SVM SVM bow3 bow3bow3：向量 特征是 特征是 uniuni -gram gramgram、bi -gram gram 和 tritritri-gram gram 特征 ，利用 ，利用 SVMSVMSVM分类 。
? CNNCNNCNN-wordword word-rand rand-static: static: static:static: 将词 级别的 级别的 词向量进行随机 词向量进行随机 词向量进行随机 词向量进行随机 初始化 。在实验过程中，词向 。在实验过程中，词向 。在实验过程中，词向 。在实验过程中，词向 。在实验过程中，词向 。在实验过程中，词向 量保持 不变 ，只学习模型的其他参数。 ，只学习模型的其他参数。 ，只学习模型的其他参数。 ，只学习模型的其他参数。 ，只学习模型的其他参数。 ，只学习模型的其他参数。
? CNNCNNCNN-wordword word-rand rand-non non-static: static: static: static: static: 将词 级别的 词向量进行随机 词向量进行随机 词向量进行随机 初始化 。在实验过程中， 。在实验过程中， 。在实验过程中， 词向量会被微调，同时学习模型的其他参数。 词向量会被微调，同时学习模型的其他参数。 词向量会被微调，同时学习模型的其他参数。 词向量会被微调，同时学习模型的其他参数。 词向量会被微调，同时学习模型的其他参数。 词向量会被微调，同时学习模型的其他参数。 词向量会被微调，同时学习模型的其他参数。 词向量会被微调，同时学习模型的其他参数。 词向量会被微调，同时学习模型的其他参数。
? CNNCNNCNN-wordword word-static: static: static:static: 利用 word2vecword2vecword2vecword2vec word2vec 训练出的词级别向量进行试验。在实过程 训练出的词级别向量进行试验。在实过程 训练出的词级别向量进行试验。在实过程 训练出的词级别向量进行试验。在实过程 训练出的词级别向量进行试验。在实过程 训练出的词级别向量进行试验。在实过程 训练出的词级别向量进行试验。在实过程 训练出的词级别向量进行试验。在实过程 训练出的词级别向量进行试验。在实过程 训练出的词级别向量进行试验。在实过程 训练出的词级别向量进行试验。在实过程 中，词向量保持不变只学习模型的其他参数。 中，词向量保持不变只学习模型的其他参数。 中，词向量保持不变只学习模型的其他参数。 中，词向量保持不变只学习模型的其他参数。 中，词向量保持不变只学习模型的其他参数。 中，词向量保持不变只学习模型的其他参数。 中，词向量保持不变只学习模型的其他参数。 中，词向量保持不变只学习模型的其他参数。 中，词向量保持不变只学习模型的其他参数。 中，词向量保持不变只学习模型的其他参数。
? CNNCNNCNN-wordword word-non non-static: static: static:static: 利用 word2vecword2vec word2vec word2vec 训练出的词级别向量进行试验 。在实训练出的词级别向量进行试验 。在实训练出的词级别向量进行试验 。在实训练出的词级别向量进行试验 。在实训练出的词级别向量进行试验 。在实训练出的词级别向量进行试验 。在实训练出的词级别向量进行试验 。在实训练出的词级别向量进行试验 。在实训练出的词级别向量进行试验 。在实训练出的词级别向量进行试验 。在实训练出的词级别向量进行试验 。在实过程中，词向量会被微调同时学习模型的其他参数。 过程中，词向量会被微调同时学习模型的其他参数。 过程中，词向量会被微调同时学习模型的其他参数。 过程中，词向量会被微调同时学习模型的其他参数。 过程中，词向量会被微调同时学习模型的其他参数。 过程中，词向量会被微调同时学习模型的其他参数。 过程中，词向量会被微调同时学习模型的其他参数。 过程中，词向量会被微调同时学习模型的其他参数。 过程中，词向量会被微调同时学习模型的其他参数。 过程中，词向量会被微调同时学习模型的其他参数。 过程中，词向量会被微调同时学习模型的其他参数。
? CNNCNNCNN-charactercharacter character character -static: static: static:static: 利用 word2vecword2vec word2vec word2vec 训练出的字级别词向量进行实验 。在训练出的字级别词向量进行实验 。在训练出的字级别词向量进行实验 。在训练出的字级别词向量进行实验 。在训练出的字级别词向量进行实验 。在训练出的字级别词向量进行实验 。在训练出的字级别词向量进行实验 。在训练出的字级别词向量进行实验 。在训练出的字级别词向量进行实验 。在过程中，词向量保持不变只学习模型的其他参数。 过程中，词向量保持不变只学习模型的其他参数。 过程中，词向量保持不变只学习模型的其他参数。 过程中，词向量保持不变只学习模型的其他参数。 过程中，词向量保持不变只学习模型的其他参数。 过程中，词向量保持不变只学习模型的其他参数。 过程中，词向量保持不变只学习模型的其他参数。 过程中，词向量保持不变只学习模型的其他参数。 过程中，词向量保持不变只学习模型的其他参数。 过程中，词向量保持不变只学习模型的其他参数。 过程中，词向量保持不变只学习模型的其他参数。
? CNNCNNCNN-charactercharacter character character -non non-static: static: static: static: static: 利用 word2vecword2vec word2vec word2vec 训练出的字级别词向量进行试验。在 训练出的字级别词向量进行试验。在 训练出的字级别词向量进行试验。在 训练出的字级别词向量进行试验。在 训练出的字级别词向量进行试验。在 训练出的字级别词向量进行试验。在 训练出的字级别词向量进行试验。在 训练出的字级别词向量进行试验。在 实验过程中，词向量会被微调同时学习模型的其他参数。 实验过程中，词向量会被微调同时学习模型的其他参数。 实验过程中，词向量会被微调同时学习模型的其他参数。 实验过程中，词向量会被微调同时学习模型的其他参数。 实验过程中，词向量会被微调同时学习模型的其他参数。 实验过程中，词向量会被微调同时学习模型的其他参数。 实验过程中，词向量会被微调同时学习模型的其他参数。 实验过程中，词向量会被微调同时学习模型的其他参数。 实验过程中，词向量会被微调同时学习模型的其他参数。 实验过程中，词向量会被微调同时学习模型的其他参数。 实验过程中，词向量会被微调同时学习模型的其他参数。 实验过程中，词向量会被微调同时学习模型的其他参数。
各个 模型的实验结果如表 模型的实验结果如表 模型的实验结果如表 模型的实验结果如表 模型的实验结果如表 模型的实验结果如表 4所示 。
表 4 不同模型的准确率
Tab.Tab.Tab.Tab.4 Accuracy of different modelsAccuracy of different modelsAccuracy of different modelsAccuracy of different modelsAccuracy of different models Accuracy of different modelsAccuracy of different modelsAccuracy of different modelsAccuracy of different modelsAccuracy of different modelsAccuracy of different modelsAccuracy of different modelsAccuracy of different models Accuracy of different models Accuracy of different models Accuracy of different modelsAccuracy of different models Accuracy of different modelsAccuracy of different modelsAccuracy of different modelsAccuracy of different modelsAccuracy of different models
模型
COAE COAE
SVM bow1SVM bow1SVM bow1SVM bow1SVM bow1SVM bow1SVM bow1SVM bow1
89. 3689. 3689. 3689. 3689. 3689. 36
SVM bow2SVM bow2SVM bow2SVM bow2SVM bow2SVM bow2SVM bow2SVM bow2
SVM bow3SVM bow3SVM bow3SVM bow3SVM bow3SVM bow3SVM bow3SVM bow3
91.7491.7491.7491.7491.74
92.1392.1392.1392.1392.13
CNN -wordwordword -rand randrand-static static static
91.9491.9491.9491.9491.94
CNN -wordwordword -rand randrand-nonnonnon-static static static
93.0693.0693.0693.0693.06
CNN -wordwordword -static static static
CNN -wordwordword -nonnonnon-static static static
93.8093.8093.8093.8093.80
94.6594.6594.6594.6594.65
CNN -charactercharactercharactercharacter charactercharacter character-static static static
94.2994.2994.2994.2994.29
CNN -charactercharactercharactercharacter charactercharacter character-non -static static static
95.495.495.495.42
4．4．1 Random vs. word2vecandom vs. word2vec andom vs. word2vec andom vs. word2vec andom vs. word2vecandom vs. word2vec
通过比较 通过比较 CNNCNNCNN-wordword word-randrand -staticstaticstatic staticstatic（93. 06 %）和 CNNCNNCNN-wordword word-stat statstatic （93. 80 %）的准确率， 的准确率， 的准确率， 可 以发现 ，利用预训练 利用预训练 利用预训练 的词向量 的词向量 的词向量 作为 原始输入进行情感 原始输入进行情感 原始输入进行情感 原始输入进行情感 倾向性 分析的准确率要 分析的准确率要 分析的准确率要 分析的准确率要 高于利用随机初 高于利用随机初 高于利用随机初 高于利用随机初 始化 的词向量 的词向量 的词向量 作为 原始输入 原始输入 原始输入 进行的 进行的 情感 倾向性 倾向性 分析的准确率 分析的准确率 分析的准确率 。原因在于利用 。原因在于利用 。原因在于利用 。原因在于利用 。原因在于利用 word2vecword2vec word2vec word2vec 工具 训练 出的词向量 出的词向量 出的词向量 包含 了上下文 上下文 语义信息 语义信息 ，因此 在进行句子情感分析时可以得到更好的效果。 在进行句子情感分析时可以得到更好的效果。 在进行句子情感分析时可以得到更好的效果。 在进行句子情感分析时可以得到更好的效果。 在进行句子情感分析时可以得到更好的效果。 在进行句子情感分析时可以得到更好的效果。 在进行句子情感分析时可以得到更好的效果。 在进行句子情感分析时可以得到更好的效果。 实验表明 实验表明 ，利用 卷积 神经网络模型 神经网络模型 神经网络模型 进行自然语言处理时，无监督方式预训练的词向量是十分 进行自然语言处理时，无监督方式预训练的词向量是十分 进行自然语言处理时，无监督方式预训练的词向量是十分 进行自然语言处理时，无监督方式预训练的词向量是十分 进行自然语言处理时，无监督方式预训练的词向量是十分 进行自然语言处理时，无监督方式预训练的词向量是十分 进行自然语言处理时，无监督方式预训练的词向量是十分 进行自然语言处理时，无监督方式预训练的词向量是十分 进行自然语言处理时，无监督方式预训练的词向量是十分 进行自然语言处理时，无监督方式预训练的词向量是十分 进行自然语言处理时，无监督方式预训练的词向量是十分 进行自然语言处理时，无监督方式预训练的词向量是十分 重要的。 重要的。
4．4．2 Static vs. Non Static vs. Non Static vs. Non Static vs. Non -static
通过比较 CNNCNNCNN-character character character -static static staticstatic（ 94.29% ） 和 CNNCNNCNN-character character character -non -static static staticstatic（ 95.4 2%）， CNNCNNCNN-wordword word-static static staticstatic（93.80% ）和 CNNCNNCNN-wordword word-non -stat stat ic （94.65% 94.65% ），CNNCNNCNN-wordword word-randrand -staticstaticstatic staticstatic（91.94% ） 和 CNNCNNCNN-wordword word-randrand -non -static static staticstatic（93.06% ）的准确率， 的准确率， 可以 发现 ，在卷积 在卷积 神经网络的训 神经网络的训 练过程 练过程 中对预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 预训练的词向量进行微调，可以一步提升模型准确率。 实验 表明， 在模型训练 模型训练 过程 中对 词向量进行微调，可以 词向量进行微调，可以 词向量进行微调，可以 词向量进行微调，可以 词向量进行微调，可以 词向量进行微调，可以 词向量进行微调，可以 让预训练 让预训练 的词向量更加适应于专门语料 的词向量更加适应于专门语料 的词向量更加适应于专门语料 的词向量更加适应于专门语料 的词向量更加适应于专门语料 的词向量更加适应于专门语料 的词向量更加适应于专门语料 ，从而 进一步 提高准确 提高准确 率。
4．4．3 Character Character Character -level vs. Word level vs. Wordlevel vs. Word level vs. Word -level level
通过比较 CNNCNNCNN-wordword word-staticstaticstatic staticstatic（ 93.80% ）和 CNNCNNCNN-character character character -staticstaticstatic staticstatic（ 94.29% ）， CNNCNNCNN-wordword word-non -staticstaticstatic staticstatic（94.65% ）和 CNNCNNCNN-character character character -non -static static staticstatic（95.4 2%）的准确率，可以 ）的准确率，可以 ）的准确率，可以 ）的准确率，可以 ）的准确率，可以 发现 ， 使用 字级别 字级别 词向量 词向量 作为原始特征要好于使用词级别向量。 作为原始特征要好于使用词级别向量。 作为原始特征要好于使用词级别向量。 作为原始特征要好于使用词级别向量。 作为原始特征要好于使用词级别向量。 作为原始特征要好于使用词级别向量。 作为原始特征要好于使用词级别向量。 作为原始特征要好于使用词级别向量。 作为原始特征要好于使用词级别向量。 作为原始特征要好于使用词级别向量。 作为原始特征要好于使用词级别向量。 作为原始特征要好于使用词级别向量。 实验 表明， 表明， 对于中 对于中 文语料而言，使用字级别词向量作为 文语料而言，使用字级别词向量作为 文语料而言，使用字级别词向量作为 文语料而言，使用字级别词向量作为 文语料而言，使用字级别词向量作为 文语料而言，使用字级别词向量作为 文语料而言，使用字级别词向量作为 原始 特征会好于使用 特征会好于使用 特征会好于使用 词级别 词级别 词向量作为 词向量作为 词向量作为 原始特征 原始特征 。
结合实验果及分析原因主要在于：字 结合实验果及分析原因主要在于：字 结合实验果及分析原因主要在于：字 结合实验果及分析原因主要在于：字 结合实验果及分析原因主要在于：字 结合实验果及分析原因主要在于：字 结合实验果及分析原因主要在于：字 结合实验果及分析原因主要在于：字 级别 特征的粒度比词级别小，字 特征的粒度比词级别小，字 特征的粒度比词级别小，字 特征的粒度比词级别小，字 特征的粒度比词级别小，字 特征的粒度比词级别小，字 特征的粒度比词级别小，字 特征的粒度比词级别小，字 级别 词向量相 词向量相 比于词级别向量可以学习到更加 比于词级别向量可以学习到更加 比于词级别向量可以学习到更加 比于词级别向量可以学习到更加 比于词级别向量可以学习到更加 比于词级别向量可以学习到更加 比于词级别向量可以学习到更加 具体 的特征 的特征 。
表 5展示了利用 展示了利用 word2vecword2vec word2vec word2vec 工具训练的字级别词向量相加得到似度与 工具训练的字级别词向量相加得到似度与 工具训练的字级别词向量相加得到似度与 工具训练的字级别词向量相加得到似度与 工具训练的字级别词向量相加得到似度与 工具训练的字级别词向量相加得到似度与 工具训练的字级别词向量相加得到似度与 工具训练的字级别词向量相加得到似度与 工具训练的字级别词向量相加得到似度与 工具训练的字级别词向量相加得到似度与 工具训练的字级别词向量相加得到似度与 工具训练的字级别词向量相加得到似度与 直接用 直接用 word2vecword2vec word2vec word2vec 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 工具训练得到的词级别向量相似度之间比较。通过对可以出利用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 字级别词向量相加得到的之间似度要高于直接用 word2veword2ve word2ve word2vec工具训练得到 工具训练得到 工具训练得到 的词级别向量之间相似度 的词级别向量之间相似度 的词级别向量之间相似度 的词级别向量之间相似度 的词级别向量之间相似度 的词级别向量之间相似度 。
但是也存在 但是也存在 一些 词语组合 词语组合 不存在这种情况。例如 不存在这种情况。例如 不存在这种情况。例如 不存在这种情况。例如 不存在这种情况。例如 ，“三元 ，“三元 ”与“牛奶 ”之间 的相似度为 的相似度为 的相似度为 0. 783 ， 因为 “三元 ”是一个牛奶品牌，所以两者之间的相似度较高而 一个牛奶品牌，所以两者之间的相似度较高而 一个牛奶品牌，所以两者之间的相似度较高而 一个牛奶品牌，所以两者之间的相似度较高而 一个牛奶品牌，所以两者之间的相似度较高而 一个牛奶品牌，所以两者之间的相似度较高而 一个牛奶品牌，所以两者之间的相似度较高而 一个牛奶品牌，所以两者之间的相似度较高而 一个牛奶品牌，所以两者之间的相似度较高而 一个牛奶品牌，所以两者之间的相似度较高而 一个牛奶品牌，所以两者之间的相似度较高而 一个牛奶品牌，所以两者之间的相似度较高而 “三”+“ ”+“ ”+“ 元”与“牛”+“ ”+“ 奶”之间 的 相似度要小于 相似度要小于 相似度要小于 0.783 0.783 。出现 。出现 这种情况的 这种情况的 可能 原因是由于 原因是由于 原因是由于 语料 中关于“三元 关于“三元 关于“三元 关于“三元 ”的内容不多，以至 内容不多，以至 内容不多，以至 内容不多，以至 于字级别的词向量没有较好地学到 级别的词向量没有较好地学到 级别的词向量没有较好地学到 级别的词向量没有较好地学到 级别的词向量没有较好地学到 级别的词向量没有较好地学到 级别的词向量没有较好地学到 相关 的信息。 的信息。 的信息。
表 5 词向量相似度 比较
Tab.Tab.Tab.Tab.5 Vector Vector Vector Vector Vector similarity comparison similarity comparison similarity comparison similarity comparison similarity comparison similarity comparison similarity comparison similarity comparison similarity comparison similarity comparison similarity comparison similarity comparison similarity comparison similarity comparison
词语
词语
余弦相似度
手机
三星
0. 668668668
手+机
车险
三+星
保险
0.7270.7270.7270.7270.727
0.6370.6370.6370.6370.637
车+险
保+险
0.6870.6870.6870.6870.687
酸奶
牛奶
0.8050.8050.8050.8050.805
酸+奶
牛+奶
0.8510.8510.8510.8510.851
另一个原因在于：传统的 另一个原因在于：传统的 另一个原因在于：传统的 另一个原因在于：传统的 分 词技术往对微博造成歧义的切分 词技术往对微博造成歧义的切分 词技术往对微博造成歧义的切分 词技术往对微博造成歧义的切分 词技术往对微博造成歧义的切分 词技术往对微博造成歧义的切，比如：“我发现了一个 比如：“我发现了一个 比如：“我发现了一个 比如：“我发现了一个 比如：“我发现了一个 高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“高大 上网站”，在该句中，“”如果使用传统分词技术，会被切为“/上/网 站”或者“高大 站”或者“高大 站”或者“高大 站”或者“高大 站”或者“高大 /上网 /站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”，这样的切分无法体现句子正确语义，甚至后一种还将“网 站”切分导致丢失评价对象。 站”切分导致丢失评价对象。 站”切分导致丢失评价对象。 站”切分导致丢失评价对象。 站”切分导致丢失评价对象。 站”切分导致丢失评价对象。 而将字 而将字 级别特征作为 级别特征作为 级别特征作为 输入 ，通过并行的卷积层可以学习到 ，通过并行的卷积层可以学习到 ，通过并行的卷积层可以学习到 ，通过并行的卷积层可以学习到 ，通过并行的卷积层可以学习到 ，通过并行的卷积层可以学习到 ，通过并行的卷积层可以学习到 不同 N-gram gram 的信息 ，例如 “高大上 高大上 ”（N=3 ）、“高大上 高大上 网站 ”（N=5 ）。本文分别用 本文分别用 本文分别用 Jieba Jieba 分词工具 分词工具 和 ICTALASICTALASICTALASICTALASICTALASICTALASICTALAS分词工具进行，得到了相近的实验结果。 分词工具进行，得到了相近的实验结果。 分词工具进行，得到了相近的实验结果。 分词工具进行，得到了相近的实验结果。 分词工具进行，得到了相近的实验结果。 分词工具进行，得到了相近的实验结果。 分词工具进行，得到了相近的实验结果。 分词工具进行，得到了相近的实验结果。 分词工具进行，得到了相近的实验结果。
4．4．4 Bag Bag-of -N-gram vs. CNNgram vs. CNN gram vs. CNNgram vs. CNN
通过 比较 SVM SVM SVM SVM bow3 bow3（92.13% 92.13%92.13% ）和 CNNCNNCNN-character character character -non -staticstaticstatic staticstatic（95.42% ）的准确率 准确率 ，可以 ，可以 ，可以 发现 ，在微博情感倾向性分析中卷积神经网络模型要 ，在微博情感倾向性分析中卷积神经网络模型要 ，在微博情感倾向性分析中卷积神经网络模型要 ，在微博情感倾向性分析中卷积神经网络模型要 ，在微博情感倾向性分析中卷积神经网络模型要 ，在微博情感倾向性分析中卷积神经网络模型要 ，在微博情感倾向性分析中卷积神经网络模型要 ，在微博情感倾向性分析中卷积神经网络模型要 ，在微博情感倾向性分析中卷积神经网络模型要 ，在微博情感倾向性分析中卷积神经网络模型要 ，在微博情感倾向性分析中卷积神经网络模型要 ，在微博情感倾向性分析中卷积神经网络模型要 ，在微博情感倾向性分析中卷积神经网络模型要 优于 传统的词袋模型。 传统的词袋模型。 传统的词袋模型。 传统的词袋模型。 传统的词袋模型。 通过 比较 SVM SVM SVM SVM bow1 bow1（89.36%89.36% ）、SVM bow2 SVM bow2 SVM bow2（91.74% 91.74% ）和 SVM bow3 SVM bow3 SVM bow3（92.31% ）的准确率， 可以发现）的准确率， 可以发现）的准确率， 可以发现）的准确率， 可以发现）的准确率， 可以发现）的准确率， 可以发现）的准确率， 可以发现bi -gram gram 和 tritritri-gram gramgram特征 让准确率有了明显提升。而 准确率有了明显提升。而 准确率有了明显提升。而 准确率有了明显提升。而 准确率有了明显提升。而 准确率有了明显提升。而 当 N较大时， 较大时， 会造成维度灾难，导致模型 造成维度灾难，导致模型 造成维度灾难，导致模型 造成维度灾难，导致模型 造成维度灾难，导致模型 造成维度灾难，导致模型 难以训 难以训 练。而 包含 多个 并行 卷积层的神经网络，可以利用不同 卷积层的神经网络，可以利用不同 卷积层的神经网络，可以利用不同 卷积层的神经网络，可以利用不同 卷积层的神经网络，可以利用不同 卷积层的神经网络，可以利用不同 卷积层的神经网络，可以利用不同 卷积层的神经网络，可以利用不同 大小 的卷积核学习不同 的卷积核学习不同 的卷积核学习不同 的卷积核学习不同 的卷积核学习不同 N-gram gram 的信息， 的信息， 通过 池化操作降低维度，从而使得模型的准确率以提高。 池化操作降低维度，从而使得模型的准确率以提高。 池化操作降低维度，从而使得模型的准确率以提高。 池化操作降低维度，从而使得模型的准确率以提高。 池化操作降低维度，从而使得模型的准确率以提高。 池化操作降低维度，从而使得模型的准确率以提高。 池化操作降低维度，从而使得模型的准确率以提高。 池化操作降低维度，从而使得模型的准确率以提高。 池化操作降低维度，从而使得模型的准确率以提高。 池化操作降低维度，从而使得模型的准确率以提高。 池化操作降低维度，从而使得模型的准确率以提高。 池化操作降低维度，从而使得模型的准确率以提高。
5 总结
本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并本文探讨了利用卷积神经网络 进行微博情感倾向性分析的可，并模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 模型取得了优于传统词袋的准确率，以此证明卷积神经网络在微博情感倾向性分析中 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 的可行性。本文利用字级别词向量及卷积神经网络分取得了 95.42% 95.42% 的准 确率和 94.65% 94.65% 的准确率，实验结果可见对于 的准确率，实验结果可见对于 的准确率，实验结果可见对于 的准确率，实验结果可见对于 的准确率，实验结果可见对于 的准确率，实验结果可见对于 的准确率，实验结果可见对于 中文语料而言，利用卷积神经网络进行微博 中文语料而言，利用卷积神经网络进行微博 中文语料而言，利用卷积神经网络进行微博 中文语料而言，利用卷积神经网络进行微博 中文语料而言，利用卷积神经网络进行微博 中文语料而言，利用卷积神经网络进行微博 中文语料而言，利用卷积神经网络进行微博 中文语料而言，利用卷积神经网络进行微博 中文语料而言，利用卷积神经网络进行微博 情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于情感倾向性分析是有效的，且使用字级别词量 作为原始特征会好于作为原始特征。 作为原始特征。 作为原始特征。
参考文献
[1] Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to Pang B, Lee L. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for rating scales[C]//Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Computational Linguistics. Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115 Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115 Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115 Association for Computational Linguistics, 2005: 115 Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115 Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115 Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115 Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115 Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115 Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115Association for Computational Linguistics, 2005: 115-124.124.124.124.
[2] 梁军 , 柴玉梅 , 原慧斌 , 等. 基于深度学习的微博情感分析 基于深度学习的微博情感分析 [J]. [J]. [J]. [J]. [J]. 中文信息学报 , 2014, 28(5): 155, 2014, 28(5): 155, 2014, 28(5): 155, 2014, 28(5): 155, 2014, 28(5): 155, 2014, 28(5): 155, 2014, 28(5): 155, 2014, 28(5): 155, 2014, 28(5): 155, 2014, 28(5): 155, 2014, 28(5): 155, 2014, 28(5): 155, 2014, 28(5): 155 , 2014, 28(5): 155, 2014, 28(5): 155, 2014, 28(5): 155-161.161.161.161.
[3] 罗毅 , 李利 , 谭松波 , 等. 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 基于中文微博语料的情感倾向性分析 [J]. [J]. [J]. [J]. [J]. 山东大学报 (理学版 ), 2014, ), 2014, ), 2014, ), 2014, ), 2014, ), 2014, ), 2014, ), 2014, ), 2014, 49(11): 149(11): 149(11): 1 49(11): 149(11): 1 49(11): 1-7.
[4] LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. LeCun Y, Bottou L, Bengio et al. GradientGradient GradientGradient Gradient-based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278 Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278 Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278 Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278 Proceedings of the IEEE, 1998, 86(11): 2278 Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278 Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278 Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278Proceedings of the IEEE, 1998, 86(11): 2278-2324.2324.2324.2324.2324.
[5] Yih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for single Yih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for single Yih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for single Yih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for single Yih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for single Yih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for single Yih W, He X, Meek C. Semantic parsing for single Yih W, He X, Meek C. Semantic parsing for singleYih W, He X, Meek C. Semantic parsing for single -relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. relation question answering[C]//Proceedings of ACL. 2014.2014.2014.2014.2014.
[6] Shen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning se Shen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning se Shen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning se Shen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning se Shen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning se Shen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning seShen Y, He X, Gao J, et al. Learning se mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web mantic representations using convolutional neural networks for web search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide search[C]//Proceedings of the companion publication 23rd international conference on World wide web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373 web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373web companion. International World Wide Web Conferences Steering Committee, 2014: 373-374.374.374.374.
[7] Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling Blunsom P, Grefenstette E, Kalchbrenner N. A convolutional neural network for modelling sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. sentences[C]//Proceedings of the 52nd Annual Meeting Association for Computational Linguistics. Proceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association fo Proceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association fo Proceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association fo Proceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association fo Proceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association fo Proceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association fo Proceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association fo Proceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association fo Proceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association foProceedings of the 52nd Annual Meeting Association for Computational Linguistics, 2014. r Computational Linguistics, 2014. r Computational Linguistics, 2014.r Computational Linguistics, 2014.r Computational Linguistics, 2014.r Computational Linguistics, 2014. r Computational Linguistics, 2014.r Computational Linguistics, 2014.r Computational Linguistics, 2014. r Computational Linguistics, 2014.r Computational Linguistics, 2014. r Computational Linguistics, 2014.r Computational Linguistics, 2014.r Computational Linguistics, 2014. r Computational Linguistics, 2014.r Computational Linguistics, 2014. r Computational Linguistics, 2014.r Computational Linguistics, 2014.r Computational Linguistics, 2014.r Computational Linguistics, 2014.r Computational Linguistics, 2014.
[8] Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Collobert R, Weston J, Bottou L, et al. Natural language processing (almost) from scratch[J]. The Journal of Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493 Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493 Machine Learning Research, 2011, 12: 2493 Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493 Machine Learning Research, 2011, 12: 2493 Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493 Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493 Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493Machine Learning Research, 2011, 12: 2493-2537.2537.2537.2537.2537.
[9] dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for dos Santos C N, Gatti M. Deep convolutional neural networks for sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short sentiment analysis of short texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), texts[C]//Proceedings of the 25th International Conference on Computational Linguistics (COLING), Dublin, Ireland. 2014. Dublin, Ireland. 2014.Dublin, Ireland. 2014. Dublin, Ireland. 2014.Dublin, Ireland. 2014.Dublin, Ireland. 2014.Dublin, Ireland. 2014. Dublin, Ireland. 2014. Dublin, Ireland. 2014.Dublin, Ireland. 2014.Dublin, Ireland. 2014.Dublin, Ireland. 2014.Dublin, Ireland. 2014.Dublin, Ireland. 2014.Dublin, Ireland. 2014.Dublin, Ireland. 2014.
[10] Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014. Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.
[11] Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of Turney P D. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. reviews[C]//Proceedings of the 40th annual meeting on association for computational linguistics. Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417 Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417 Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417 Association for Computational Linguistics, 2002: 417 Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417 Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417 Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417 Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417 Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417 Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417Association for Computational Linguistics, 2002: 417-424.424.424.424.
[12] Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097 networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097networks[C]//Advances in neural information processing systems. 2012: 1097-1105.1105.1105.1105.1105.
[13] Collobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//Internationa Collobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//InternationaCollobert R. Deep learning for efficient discriminative parsing[C]//International Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial l Conference on Artificial Intelligence and Statistics. 2011 (EPFL Intelligence and Statistics. 2011 (EPFL Intelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFL Intelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFL Intelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFL Intelligence and Statistics. 2011 (EPFLIntelligence and Statistics. 2011 (EPFL-CONF CONF-192374).192374).192374).192374).192374).192374).192374).
[14] Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for Luong M T, Socher R, Manning C D. Better word representations with recursive neural networks for morphology[J]. CoNLLmorphology[J]. CoNLLmorphology[J]. CoNLL morphology[J]. CoNLLmorphology[J]. CoNLLmorphology[J]. CoNLL morphology[J]. CoNLLmorphology[J]. CoNLLmorphology[J]. CoNLLmorphology[J]. CoNLL morphology[J]. CoNLLmorphology[J]. CoNLLmorphology[J]. CoNLL morphology[J]. CoNLL morphology[J]. CoNLL-2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.2013, 2013, 104.
[15] Zheng X, Chen H, Xu T. Deep Learning for Zheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning for Zheng X, Chen H, Xu T. Deep Learning for Zheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning for Zheng X, Chen H, Xu T. Deep Learning for Zheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning for Zheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning for Zheng X, Chen H, Xu T. Deep Learning for Zheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning forZheng X, Chen H, Xu T. Deep Learning for Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. Chinese Word Segmentation and POS Tagging[C]//EMNLP. 2013: 6472013: 6472013: 6472013: 6472013: 647 2013: 6472013: 6472013: 647-657.657.657.657.
[16] Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of Socher R, Bauer J, Manning C D, et al. Parsing with compositional vector grammars[C]//In Proceedings of the ACL conference. 2013. the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013. the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013. the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.the ACL conference. 2013.
[17] Mikolov T, SutskeverMikolov T, Sutskever Mikolov T, SutskeverMikolov T, Sutskever Mikolov T, SutskeverMikolov T, SutskeverMikolov T, SutskeverMikolov T, SutskeverMikolov T, SutskeverMikolov T, SutskeverMikolov T, SutskeverMikolov T, Sutskever Mikolov T, SutskeverMikolov T, SutskeverMikolov T, SutskeverMikolov T, Sutskever I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their I, Chen K, et al. Distributed representations of words and phrases their compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111 compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111compositionality[C]//Advances in Neural Information Processing Systems. 2013: 3111-3119.3119.3119.3119.3119.
[18] Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701 Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701Zeiler M D. ADADELTA: an adaptive learning rate method[J]. arXiv preprint arXiv:1212.5701, 2012., 2012., 2012., 2012., 2012., 2012., 2012.
[19] Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Chang C C, Lin J. LIBSVM: A library for support vector machines[J]. ACM Transactions on Intelligent Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27. Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27. Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27. Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27. Systems and Technology (TIST), 2011, 2(3): 27. Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27. Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27. Systems and Technology (TIST), 2011, 2(3): 27. Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.Systems and Technology (TIST), 2011, 2(3): 27.
作者简介： 作者简介：
刘龙飞 （1989198919891989―），男，硕士研究生 ），男，硕士研究生 ），男，硕士研究生 ，主要研究领域为 机器学习、 情感计算 。
Email: Email:Email: Email: liudragonfly@mail.dlut.edu.cn liudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cn liudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cn liudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cn liudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cn liudragonfly@mail.dlut.edu.cn liudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cnliudragonfly@mail.dlut.edu.cn；
杨亮 （1986198619861986―），男 ），男 ，博士研究生 ，博士研究生 ，主要研究领域为 情感分析、自然语言理解 。
Email: Email:Email: Email: yangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cn yangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cn yangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cn yangliang@mail.dlut.edu.cn yangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cnyangliang@mail.dlut.edu.cn；
张绍武（ 1967196719671967―），男，博士副教授主要研究领域为情感计算和搜索引擎。 ），男，博士副教授主要研究领域为情感计算和搜索引擎。 ），男，博士副教授主要研究领域为情感计算和搜索引擎。
Email EmailEmail : zhangsw@dlut.edu.cnzhangsw@dlut.edu.cnzhangsw@dlut.edu.cnzhangsw@dlut.edu.cnzhangsw@dlut.edu.cnzhangsw@dlut.edu.cnzhangsw@dlut.edu.cnzhangsw@dlut.edu.cn zhangsw@dlut.edu.cn zhangsw@dlut.edu.cn zhangsw@dlut.edu.cnzhangsw@dlut.edu.cnzhangsw@dlut.edu.cnzhangsw@dlut.edu.cnzhangsw@dlut.edu.cnzhangsw@dlut.edu.cn。
林鸿飞 （1962196219621962―）， 通信作者， 通信作者， 男， 博士， 教授 ，主要研究领域为 搜索引擎、文本
挖掘、情感计算和自然语言理解 。Email: Email:Email: Email: hflinhflinhflin hflin@dlut.edu.cndlut.edu.cn dlut.edu.cn dlut.edu.cndlut.edu.cndlut.edu.cndlut.edu.cndlut.edu.cndlut.edu.cn。